## Hey there, I'm Jeremy <img src="https://media.giphy.com/media/hvRJCLFzcasrR4ia7z/giphy.gif" width="25">
* I specialize in Natural Language Processing (NLP), Active learning & rapid annotation and Algorithmic trading
* I typically work with python, torch, SpaCy, Prodigy, transformers, AllenNLP, TimeScaleDB, elasticsearch and docker.

ðŸ”— &nbsp;**Contact me on:**  
<a href="https://www.linkedin.com/in/jeremy-tan-jianle/" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/linked-in-alt.svg" alt="ramikrispin" height="30" width="40" /></a>


## Main projects
### NLP
Maybe NLP, as a whole, does not really need bigger transformers. Maybe it needs new architectures and solutions that enable models to use knowledge rapidly and reliably. I specialize in information retrieval and event extraction.   
<p align="left">
  <a href="https://github.com/aimakerspace/goldenretriever"><img width="400" src="https://github-readme-stats.vercel.app/api/pin/?username=aimakerspace&repo=goldenretriever&theme=react&bg_color=1F222E&title_color=F85D7F&icon_color=F8D866&hide_border=true&show_icons=false" alt="goldenretriever"></a>
  <a href="https://github.com/jeremytanjianle/bibliqal"><img width="400" src="https://github-readme-stats.vercel.app/api/pin/?username=jeremytanjianle&repo=bibliqal&theme=react&bg_color=1F222E&title_color=F85D7F&icon_color=F8D866&hide_border=true&show_icons=false" alt="bibliqal"></a>
    <a href="https://github.com/jeremytanjianle/fasttext-in-pytorch"><img width="400" src="https://github-readme-stats.vercel.app/api/pin/?username=jeremytanjianle&repo=fasttext-in-pytorch&theme=react&bg_color=1F222E&title_color=F85D7F&icon_color=F8D866&hide_border=true&show_icons=false" alt="fasttext-pytorch"></a>
  <a href="https://github.com/jeremytanjianle/event-extraction-oneie"><img width="400" src="https://github-readme-stats.vercel.app/api/pin/?username=jeremytanjianle&repo=event-extraction-oneie&theme=react&bg_color=1F222E&title_color=F85D7F&icon_color=F8D866&hide_border=true&show_icons=false" alt="oneie"></a>
</p>

### Data science
There has to be more to data science and machine learning than simply `magic.fit(X,y)`.  
<p align="left">
  <a href="https://github.com/jeremytanjianle/xyZee"><img width="400" src="https://github-readme-stats.vercel.app/api/pin/?username=jeremytanjianle&repo=xyZee&theme=react&bg_color=1F222E&title_color=F85D7F&icon_color=F8D866&hide_border=true&show_icons=false" alt="xyZee"></a>
</p>

### Algorithmic trading  
Active algorithmic trader since 2017. The most expensive lesson I've learnt is that that machine learning must be used in very small amounts for trading. <b>Less is more.</b>  
<p align="left">
  <a href="https://github.com/jeremytanjianle/Bayesian-Regression-on-Copper"><img width="400" src="https://github-readme-stats.vercel.app/api/pin/?username=jeremytanjianle&repo=Bayesian-Regression-on-Copper&theme=react&bg_color=1F222E&title_color=F85D7F&icon_color=F8D866&hide_border=true&show_icons=false" alt="bayesian-regression"></a>
  <a href="https://github.com/jeremytanjianle/intraday-fx-dynamics"><img width="400" src="https://github-readme-stats.vercel.app/api/pin/?username=jeremytanjianle&repo=intraday-fx-dynamics&theme=react&bg_color=1F222E&title_color=F85D7F&icon_color=F8D866&hide_border=true&show_icons=false" alt="intraday-fx"></a>
</p>


# Trading Updates
## Jul-Dec 2022: Low-Beta Strategies
Pleased to share trading results achieving 20.91% over 2022, as verified on myfxbook.com on a live account.

In Nov-Dec 2021, my systems indicated a distinct regime change, so I stopped what I was doing and set out to re-strategize specifically for this years context. This took a long 6 months and the resulting product launched from July to December with a break in October. Results in picture below.

My reflections from trading 2022:
1. Re-strategizing was rewarding but also time-consuming. Can it be done efficiently?
2. Are there better ways to integrate macroeconomic outlook into algorithmic trading?
3. Negative correlation to the S&P500 is achieved, but low intra-portfolio correlation is not guaranteed. In early November, all strategies were red, leading to a 6% drawdown.
4. I took a break in October, which according to my backtests, would have been a great month that would have helped offset the drawdown in early November. If success of algorithmic trading = capital * skill * time; I'll have to psychologically strengthen myself to not take long breaks. 

 </br>  </a>
</p>
<img src="images/2022results2.png" width="100%" align="center"/></a>
</p>

## Oct 2021: A new breed of trading algorithms
### Out-of-sample backtest results.  </br>
 Equity graph is non-compounded and unleveraged. Metrics are compounded and unleveraged. Commissions included.
<img src="images/OOS.png" width="100%" align="center"/></a>

### Live trading results. (Verified on myfxbook.com)   </br>

Strategy earned 5.3% over ~3 weeks from 18th Oct to 8th Nov. After which, the algorithms were integrated into my main portfolio. </br>  </a>
</p>
<img src="images/live-testing-oct-2021.png" width="100%" align="center"/></a>
</p>
<p align="left"> <img src="https://github-readme-stats.vercel.app/api?username=jeremytanjianle&hide=java,html,tex&theme=react&bg_color=1F222E&title_color=F85D7F&icon_color=F8D866&hide_border=true&langs_count=4)" alt="jeremytanjianle" />
